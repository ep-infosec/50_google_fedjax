{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVlzn5lPxReI"
      },
      "source": [
        "# Federated datasets\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/fedjax/blob/main/docs/notebooks/dataset_tutorial.ipynb)\n",
        "\n",
        "This tutorial introduces datasets in FedJAX and how to work with them. By completing this tutorial, we'll learn about the best practices for working with datasets.\n",
        "\n",
        "**NOTE: For datasets, we operate over NumPy arrays NOT JAX arrays.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYNAdtNu7Nlf"
      },
      "outputs": [],
      "source": [
        "# Uncomment these to install fedjax.\n",
        "# !pip install fedjax\n",
        "# !pip install --upgrade git+https://github.com/google/fedjax.git\n",
        "# !pip install tensorflow_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XANytMDXZbAH"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import itertools\n",
        "import fedjax\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnfi9sx6zC6E"
      },
      "source": [
        "## What are datasets in federated learning?\n",
        "\n",
        "In the context of federated learning (FL), data is decentralized across clients, with each client having their own local set of examples. In light of this, we refer to two levels of organization for datasets:\n",
        "\n",
        "- Federated dataset: A collection of clients, each with their own local datasets and metadata\n",
        "- Client dataset: The set of local examples for a particular client\n",
        "\n",
        "We can think of federated data as a mapping from client ids to client datasets and client datasets as a list of examples.\n",
        "\n",
        "```\n",
        "federated_data = {\n",
        "  'client0': ['a', 'b', 'c'],\n",
        "  'client1': ['d', 'e'],\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qttyzji6-LU"
      },
      "source": [
        "### Federated datasets\n",
        "\n",
        "FedJAX comes packaged with multiple federated datasets, and we will look at the Shakespeare dataset as an example. The Shakespeare dataset is created from [The Complete Works of Shakespeare](https://www.gutenberg.org/files/100/100-0.txt), by treating each character in the play as a \"client\", and their dialogue lines as the examples.\n",
        "\n",
        "FedJAX organizes federated datasets as Python modules. `load_data()` from a dataset module loads all predefined splits together as `fedjax.FederatedData` objects, the interface for accessing all federated datasets. In the case of the Shakespeare dataset, `load_data()` returns two splits: train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 613,
          "status": "ok",
          "timestamp": 1631284020792,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "fxeEfaKb3J9N",
        "outputId": "426c8776-d3e9-423c-8e3b-a87a8ecfe17c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading 'https://storage.googleapis.com/gresearch/fedjax/shakespeare/shakespeare_train.sqlite' to '/tmp/.cache/fedjax/shakespeare_train.sqlite'\n",
            "100%, elapsed: 0s\n",
            "Downloading 'https://storage.googleapis.com/gresearch/fedjax/shakespeare/shakespeare_test.sqlite' to '/tmp/.cache/fedjax/shakespeare_test.sqlite'\n",
            "100%, elapsed: 0s\n"
          ]
        }
      ],
      "source": [
        "# We cap max sentence length to 8.\n",
        "train_fd, test_fd = fedjax.datasets.shakespeare.load_data(sequence_length=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vt7LCVV_TZl"
      },
      "source": [
        "`fedjax.FederatedData` provides methods for accessing metadata about the federated dataset, like the total number of clients, client ids, and number of examples for each client.\n",
        "\n",
        "As seen in the output, there are 715 total clients in the Shakespeare dataset.\n",
        "Each client has a unique client ID that can be used to query metadata about that client such as the number of examples that client has."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 63,
          "status": "ok",
          "timestamp": 1631284022683,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "0RZVyPIA_Rrk",
        "outputId": "06a8a776-7df7-4e58-8f1a-61418f8fee22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_clients = 715\n",
            "client_id = b'00192e4d5c9c3a5b:ALL_S_WELL_THAT_ENDS_WELL_CENTURION'\n",
            "# examples = 5\n",
            "client_id = b'004309f15562402e:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_CAMPEIUS'\n",
            "# examples = 13\n",
            "client_id = b'00b20765b748920d:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_ALL'\n",
            "# examples = 15\n"
          ]
        }
      ],
      "source": [
        "print('num_clients =', train_fd.num_clients())\n",
        "\n",
        "# train_fd.client_ids() is a generator of client ids.\n",
        "# itertools has efficient and convenient functions for working with generators.\n",
        "for client_id in itertools.islice(train_fd.client_ids(), 3):\n",
        "  print('client_id =', client_id)\n",
        "  print('# examples =', train_fd.client_size(client_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8FlpRf4B2LQ"
      },
      "source": [
        "As we notice, the client ids start with a random set of bits. This is to ensure that one can easily slice a `FederatedData` to obtain a random subset. While the client ids returned above look sorted, there is no such guarantee in general."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 13,
          "status": "ok",
          "timestamp": 1631284316222,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "VFQDFsMFHWjr",
        "outputId": "5fabc9bf-8979-44ec-9ea9-42b72300b57e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_clients whose id starts with 0 = 47\n"
          ]
        }
      ],
      "source": [
        "# Slicing are based on the lexicographic order of client ids.\n",
        "train_fd_0 = train_fd.slice(start=b'0', stop=b'1')\n",
        "print('num_clients whose id starts with 0 =', train_fd_0.num_clients())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7urRdOQCFGoB"
      },
      "source": [
        "### Client datasets\n",
        "\n",
        "We can query the dataset for a client from a federated dataset using their client ID and `fedjax.FederatedData.get_client()`. The output of `fedjax.FederatedData.get_client()` is a `fedjax.ClientDataset`. A `fedjax.ClientDataset` object\n",
        "\n",
        "-   Stores all the examples for a given client and any preprocessing that should be applied on batches.\n",
        "-   Provides methods for batching, shuffling, and iterating over preprocessed examples.\n",
        "\n",
        "In other words, **ClientDataset = examples + preprocessor**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 62,
          "status": "ok",
          "timestamp": 1631284454379,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "0z6pyKBoFGXV",
        "outputId": "cf67ef23-1600-4211-81de-c215139ef71e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u003cfedjax.core.client_datasets.ClientDataset object at 0x7ff730f5afd0\u003e\n"
          ]
        }
      ],
      "source": [
        "client_id = b'105f96df763d4ddf:ALL_S_WELL_THAT_ENDS_WELL_GUIDERIUS_AND_ARVIRAGUS'\n",
        "client_dataset = train_fd.get_client(client_id)\n",
        "print(client_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx3L26llSuK2"
      },
      "source": [
        "FedJAX assumes that an individual client dataset is small and can easily fit in memory. This assumption is also reflected in many of FedJAX's design decisions. The examples in a client dataset can be viewed as a table, where the rows are\n",
        "the individual examples, and the columns are the features (labels are viewed as\n",
        "a feature in this context).\n",
        "\n",
        "FedJAX uses a column based representation when loading a dataset into memory.\n",
        "\n",
        "-   Each column is a NumPy array `x` of rank at least 1, where `x[i, ...]` is\n",
        "    the value of this feature for the `i`-th example.\n",
        "-   The complete set of examples is a dict-like object, from `str` feature\n",
        "    names, to the corresponding column values.\n",
        "\n",
        "Traditionally, a row based representation is used for representing the entire\n",
        "dataset, and a column based representation is used for a single batch.\n",
        "\n",
        "**In the context of federated learning, an individual client dataset is small\n",
        "enough to easily fit into memory so the same representation is used for the\n",
        "entire dataset and a batch.**\n",
        "\n",
        "The preprocessed examples of a single client can be viewed by calling `all_examples()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 68,
          "status": "ok",
          "timestamp": 1631285174264,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "OPegAvJlStXB",
        "outputId": "da53970a-8417-45e2-ce63-2e5fb3a1b7cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'x': array([[ 1, 55, 67, 84, 67, 47,  7, 67],\n",
              "        [48, 16, 13, 32, 33, 14, 11, 78],\n",
              "        [76, 78, 33, 19, 16, 66, 47,  3],\n",
              "        [16, 27, 67, 23, 26, 47,  3, 27],\n",
              "        [16,  7,  4, 67, 16, 51, 48, 68],\n",
              "        [ 7, 26, 47, 27, 42, 16,  7,  4],\n",
              "        [67, 72, 16, 48, 67, 27, 23, 71],\n",
              "        [67, 65, 29, 79, 76, 51, 74, 12],\n",
              "        [75, 54, 74, 19, 16, 66, 47,  3],\n",
              "        [16, 67,  8, 67, 71, 47,  7, 61],\n",
              "        [16, 14,  4, 67, 47, 16, 48, 67],\n",
              "        [84, 67, 47,  7, 67, 48, 16, 12],\n",
              "        [78, 29, 75, 78, 33, 16, 66, 47],\n",
              "        [ 3, 16, 75, 73, 29, 11, 75, 76],\n",
              "        [32, 19, 65, 16, 16, 16, 16, 16],\n",
              "        [16, 16, 16, 16, 16, 16, 16, 16],\n",
              "        [16, 16, 16, 16, 16, 16, 16, 16],\n",
              "        [28, 68,  7,  4, 16, 75, 76, 32],\n",
              "        [30, 74, 54, 65,  0,  0,  0,  0]], dtype=int32),\n",
              " 'y': array([[55, 67, 84, 67, 47,  7, 67, 48],\n",
              "        [16, 13, 32, 33, 14, 11, 78, 76],\n",
              "        [78, 33, 19, 16, 66, 47,  3, 16],\n",
              "        [27, 67, 23, 26, 47,  3, 27, 16],\n",
              "        [ 7,  4, 67, 16, 51, 48, 68,  7],\n",
              "        [26, 47, 27, 42, 16,  7,  4, 67],\n",
              "        [72, 16, 48, 67, 27, 23, 71, 67],\n",
              "        [65, 29, 79, 76, 51, 74, 12, 75],\n",
              "        [54, 74, 19, 16, 66, 47,  3, 16],\n",
              "        [67,  8, 67, 71, 47,  7, 61, 16],\n",
              "        [14,  4, 67, 47, 16, 48, 67, 84],\n",
              "        [67, 47,  7, 67, 48, 16, 12, 78],\n",
              "        [29, 75, 78, 33, 16, 66, 47,  3],\n",
              "        [16, 75, 73, 29, 11, 75, 76, 32],\n",
              "        [19, 65, 16, 16, 16, 16, 16, 16],\n",
              "        [16, 16, 16, 16, 16, 16, 16, 16],\n",
              "        [16, 16, 16, 16, 16, 16, 16, 28],\n",
              "        [68,  7,  4, 16, 75, 76, 32, 30],\n",
              "        [74, 54, 65,  2,  0,  0,  0,  0]], dtype=int32)}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client_dataset.all_examples()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usL6TCyiTFbl"
      },
      "source": [
        "For Shakespeare, we are training a character-level language model, where the task is next character prediction, so the features are:\n",
        "\n",
        "- `x` is a list of right-shifted sentences, e.g. `sentence[:-1]`\n",
        "- `y` is a list of left-shifted sentences, e.g. `sentence[1:]`\n",
        "\n",
        "This way, `y[i][j]` corresponds to the next character after `x[i][j]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 58,
          "status": "ok",
          "timestamp": 1631285177059,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "TrEBFCwhVbF5",
        "outputId": "3a226770-12c7-47b4-e9d4-3e0c867265f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x [ 1 55 67 84 67 47  7 67]\n",
            "y [55 67 84 67 47  7 67 48]\n"
          ]
        }
      ],
      "source": [
        "examples = client_dataset.all_examples()\n",
        "print('x', examples['x'][0])\n",
        "print('y', examples['y'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joe6K_cnVZuj"
      },
      "source": [
        "However, you probably noticed that `x` and `y` are arrays of integers not text. This is because  `fedjax.datasets.shakespeare.load_data()` does some minimal preprocessing, such as a simple character look up that mapped characters to integer IDs. Later, we'll go over how this preprocessing was applied and how to add your own custom preprocessing.\n",
        "\n",
        "For comparison, here's the unprocessed version of the same client dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 115,
          "status": "ok",
          "timestamp": 1631285179288,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "qJ41cLCUS1GA",
        "outputId": "25ccc700-510f-4a19-9ce7-eeae7a12a416"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing cached file '/tmp/.cache/fedjax/shakespeare_train.sqlite'\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'snippets': array([b'Re-enter POSTHUMUS, and seconds the Britons; they rescue\\nCYMBELINE, and exeunt. Then re-enter LUCIUS and IACHIMO,\\n                     with IMOGEN\\n'],\n",
              "       dtype=object)}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Unlike load_data(), load_split() always loads a single unprocessed split.\n",
        "raw_fd = fedjax.datasets.shakespeare.load_split('train')\n",
        "raw_fd.get_client(client_id).all_examples()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4urvo2ffUsA"
      },
      "source": [
        "## Accessing client datasets from `fedjax.FederatedData`\n",
        "\n",
        "`fedjax.FederatedData.get_client()` works well for querying data for a *single* client for exploring the dataset. However, we often want to query for multiple client datasets at the same time. In most FL algorithms, tens to hundreds of clients particpate in each training round. If we are not careful, our code can spend a lot of time loading data, leaving the accelerators (GPU or TPU) to idle.\n",
        "\n",
        "In light of this, `fedjax.FederatedData` offers more efficient methods for querying multiple client datasets.\n",
        "\n",
        "**We'll go through each access method from the MOST efficient to the LEAST efficient.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fknJ_vA_L1er"
      },
      "source": [
        "### `clients()` and `shuffled_clients()`\n",
        "\n",
        "**Fastest** sequential read friendly access. As we stated earlier, the client ids are appended with random bits. Hene, even sequential reads will go over clients in a pseudo-random order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 11,
          "status": "ok",
          "timestamp": 1631285239199,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "48iWUX-0Il52",
        "outputId": "1ebbc8df-a5ef-41eb-9a53-97a33b324b97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clients = \u003cgenerator object SQLiteFederatedData.clients at 0x7ff730f3d950\u003e\n",
            "shuffled_clients = \u003cgenerator object SQLiteFederatedData.shuffled_clients at 0x7ff7310a8950\u003e\n"
          ]
        }
      ],
      "source": [
        "# clients() and shuffled_clients() are sequential read friendly.\n",
        "clients = train_fd.clients()\n",
        "shuffled_clients = train_fd.shuffled_clients(buffer_size=100, seed=0)\n",
        "print('clients =', clients)\n",
        "print('shuffled_clients =', shuffled_clients)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7-bQUKPLunl"
      },
      "source": [
        "They are generators, so we iterate over them to get the individual client datasets as tuples of (client_id, client_dataset).\n",
        "\n",
        "`clients()` returns clients in an unspecified deterministic order. It is useful for going over the entire federated dataset for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 60,
          "status": "ok",
          "timestamp": 1631285241992,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "9IFLDlocLwTV",
        "outputId": "67443f23-9ff8-494d-e500-8a97481050f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client_id = b'00192e4d5c9c3a5b:ALL_S_WELL_THAT_ENDS_WELL_CENTURION'\n",
            "# examples = 53\n",
            "client_id = b'004309f15562402e:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_CAMPEIUS'\n",
            "# examples = 234\n",
            "client_id = b'00b20765b748920d:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_ALL'\n",
            "# examples = 79\n"
          ]
        }
      ],
      "source": [
        "# We use itertools.islice to select first three clients.\n",
        "for client_id, client_dataset in itertools.islice(clients, 3):\n",
        "  print('client_id =', client_id)\n",
        "  print('# examples =', len(client_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTGrSHMUMLzJ"
      },
      "source": [
        "`shuffled_clients()` provides a stream of infinitely repeating shuffled client datasets, using buffered shuffling. It is suitable for training rounds where a nearly random shuffling is good enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 108,
          "status": "ok",
          "timestamp": 1631285243933,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "JTFJO7k1MOr4",
        "outputId": "1ac6c558-8616-459b-b5f1-a52e9a7618e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shuffled_clients()\n",
            "client_id = b'0a18c2501d441fef:THE_TRAGEDY_OF_KING_LEAR_FLUTE'\n",
            "# examples = 115\n",
            "client_id = b'136c5586b7271525:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_GLOUCESTER'\n",
            "# examples = 3804\n",
            "client_id = b'0d642a9b4bb27187:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_MESSENGER'\n",
            "# examples = 775\n"
          ]
        }
      ],
      "source": [
        "print('shuffled_clients()')\n",
        "for client_id, client_dataset in itertools.islice(shuffled_clients, 3):\n",
        "  print('client_id =', client_id)\n",
        "  print('# examples =', len(client_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGd1NDhJMW8R"
      },
      "source": [
        "### `get_clients()`\n",
        "\n",
        "**Slower** than `clients()` since it requires random read but uses prefetching to hide the latency of random read access. This also returns a generator of tuples of (client_id, client_dataset), in the order of the input client_ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 64,
          "status": "ok",
          "timestamp": 1631285246073,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "WGTz8aotMn9Q",
        "outputId": "a923cf6c-fba3-47e1-ce9e-8be927f7ebcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client_id = b'1db830204507458e:THE_TAMING_OF_THE_SHREW_SEBASTIAN'\n",
            "# examples = 483\n",
            "client_id = b'140784b36d08efbc:PERICLES__PRINCE_OF_TYRE_GHOST_OF_VAUGHAN'\n",
            "# examples = 5\n",
            "client_id = b'105f96df763d4ddf:ALL_S_WELL_THAT_ENDS_WELL_GUIDERIUS_AND_ARVIRAGUS'\n",
            "# examples = 19\n"
          ]
        }
      ],
      "source": [
        "client_ids = [\n",
        "    b'1db830204507458e:THE_TAMING_OF_THE_SHREW_SEBASTIAN',\n",
        "    b'140784b36d08efbc:PERICLES__PRINCE_OF_TYRE_GHOST_OF_VAUGHAN',\n",
        "    b'105f96df763d4ddf:ALL_S_WELL_THAT_ENDS_WELL_GUIDERIUS_AND_ARVIRAGUS'\n",
        "]\n",
        "for client_id, client_dataset in train_fd.get_clients(client_ids):\n",
        "  print('client_id =', client_id)\n",
        "  print('# examples =', len(client_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK6EV1zTMoWE"
      },
      "source": [
        "### `get_client()`\n",
        "\n",
        "**Slowest** way of accessing client datasets. We usually reserve this method only for interactive exploration of a small number of clients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 57,
          "status": "ok",
          "timestamp": 1631285251208,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "MNaCOkFnM6JU",
        "outputId": "022bfd23-fc63-49ed-e8fe-a3632c64aee6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client_id = b'1db830204507458e:THE_TAMING_OF_THE_SHREW_SEBASTIAN'\n",
            "# examples = 483\n"
          ]
        }
      ],
      "source": [
        "client_id = b'1db830204507458e:THE_TAMING_OF_THE_SHREW_SEBASTIAN'\n",
        "print('client_id =', client_id)\n",
        "print('# examples =', len(train_fd.get_client(client_id)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7r5jfm0V2YH"
      },
      "source": [
        "## Batching client datasets\n",
        "\n",
        "Next we'll go over different methods of iterating over a `fedjax.ClientDataset` as batched examples. All the following methods can be invoked in 2 ways:\n",
        "\n",
        "-   Using a hyperparams object: This is the recommended way in library code. `batch_fn(hparams)`.\n",
        "-   Using keyword arguments: The keyword arguments are used to construct a new hyperparams object, or override an existing one. `batch_fn(batch_size=2)` or `batch_fn(hparams, batch_size=2)` to override `batch_size`.\n",
        "\n",
        "For the most part, we'll use method 2 for this colab, but method 1 is more suitable for writing library code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcGaaGkXf5lz"
      },
      "outputs": [],
      "source": [
        "client_id = b'105f96df763d4ddf:ALL_S_WELL_THAT_ENDS_WELL_GUIDERIUS_AND_ARVIRAGUS'\n",
        "client_dataset = train_fd.get_client(client_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGyLXbxYDozu"
      },
      "source": [
        "### `batch()` for illustrations\n",
        "\n",
        "Produces preprocessed batches in a fixed sequential order.\n",
        "\n",
        "The final batch may contain fewer than `batch_size` examples. If used directly,\n",
        "that may result in a large number of JIT recompilations. **Therefore we\n",
        "should use `padded_batch()` or `shuffle_repeat_batch()` instead in most scenarios.**\n",
        "\n",
        "Note here we are not talking about padding within an example, often done in processing sequence examples (e.g. the 0 labels below), but rather padding with \"empty\" examples in a batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1631285261201,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "opnvtWCODpGX",
        "outputId": "9f80296d-bba6-4e31-8dfc-b9fdbae23fe1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'x': array([[16, 16, 16, 16, 16, 16, 16, 16],\n",
              "        [28, 68,  7,  4, 16, 75, 76, 32],\n",
              "        [30, 74, 54, 65,  0,  0,  0,  0]], dtype=int32),\n",
              " 'y': array([[16, 16, 16, 16, 16, 16, 16, 28],\n",
              "        [68,  7,  4, 16, 75, 76, 32, 30],\n",
              "        [74, 54, 65,  2,  0,  0,  0,  0]], dtype=int32)}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batches = list(client_dataset.batch(batch_size=8))\n",
        "batches[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y2qFa8HVyar"
      },
      "source": [
        "### `padded_batch()` for evaluation\n",
        "\n",
        "Produces preprocessed padded batches in a fixed sequential order **for evaluation**.\n",
        "\n",
        "When the number of examples in the dataset is not a multiple of `batch_size`,\n",
        "the final batch may be smaller than `batch_size`. This may lead to [a large\n",
        "number of JIT recompilations](https://jax.readthedocs.io/en/latest/jax-101/02-jitting.html). This can be circumvented by padding the final\n",
        "batch to a small number of fixed sizes controlled by `num_batch_size_buckets`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 63,
          "status": "ok",
          "timestamp": 1631285264406,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "cRPnF2YOXU6e",
        "outputId": "d45ccae0-36b3-496d-cb1f-e6b01be7ecb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# batches = 3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'x': array([[ 1, 55, 67, 84, 67, 47,  7, 67],\n",
              "        [48, 16, 13, 32, 33, 14, 11, 78],\n",
              "        [76, 78, 33, 19, 16, 66, 47,  3],\n",
              "        [16, 27, 67, 23, 26, 47,  3, 27],\n",
              "        [16,  7,  4, 67, 16, 51, 48, 68],\n",
              "        [ 7, 26, 47, 27, 42, 16,  7,  4],\n",
              "        [67, 72, 16, 48, 67, 27, 23, 71],\n",
              "        [67, 65, 29, 79, 76, 51, 74, 12]], dtype=int32),\n",
              " 'y': array([[55, 67, 84, 67, 47,  7, 67, 48],\n",
              "        [16, 13, 32, 33, 14, 11, 78, 76],\n",
              "        [78, 33, 19, 16, 66, 47,  3, 16],\n",
              "        [27, 67, 23, 26, 47,  3, 27, 16],\n",
              "        [ 7,  4, 67, 16, 51, 48, 68,  7],\n",
              "        [26, 47, 27, 42, 16,  7,  4, 67],\n",
              "        [72, 16, 48, 67, 27, 23, 71, 67],\n",
              "        [65, 29, 79, 76, 51, 74, 12, 75]], dtype=int32),\n",
              " '__mask__': array([ True,  True,  True,  True,  True,  True,  True,  True])}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use list() to consume generator and store in memory.\n",
        "padded_batches = list(client_dataset.padded_batch(batch_size=8, num_batch_size_buckets=3))\n",
        "print('# batches =', len(padded_batches))\n",
        "padded_batches[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WzTr7zBXVPj"
      },
      "source": [
        "All batches contain an extra bool feature keyed by `'__mask__'`.\n",
        "`batch['__mask__'][i]` tells us whether the `i`-th example in this batch\n",
        "is an actual example (`batch['__mask__'][i] == True`), or a padding\n",
        "example (`batch['__mask__'][i] == False`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zMXxpp8ZN5F"
      },
      "source": [
        "We repeatedly halve the batch size up to `num_batch_size_buckets - 1` times, until\n",
        "we find the smallest one that is also \u003e= the size of the final batch. Therefore\n",
        "if `batch_size \u003c 2^num_batch_size_buckets`, fewer bucket sizes will be actually\n",
        "used. This will be seen when we look at the final batch that only has 4 examples when the original batch size was 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 134,
          "status": "ok",
          "timestamp": 1631285619530,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "NwqYDivRZR4T",
        "outputId": "99c535bc-4668-4adf-9ead-24877647c271"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'__mask__': array([ True,  True,  True, False]),\n",
              " 'x': array([[16, 16, 16, 16, 16, 16, 16, 16],\n",
              "        [28, 68,  7,  4, 16, 75, 76, 32],\n",
              "        [30, 74, 54, 65,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0]], dtype=int32),\n",
              " 'y': array([[16, 16, 16, 16, 16, 16, 16, 28],\n",
              "        [68,  7,  4, 16, 75, 76, 32, 30],\n",
              "        [74, 54, 65,  2,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0]], dtype=int32)}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_batches[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49yb3Bh3Ue4m"
      },
      "source": [
        "### `shuffle_repeat_batch()` for training\n",
        "\n",
        "Produces preprocessed batches in a shuffled and repeated order **for training**.\n",
        "\n",
        "Shuffling is done without replacement, therefore for a dataset of N examples,\n",
        "the first `ceil(N/batch_size)` batches are guarranteed to cover the entire\n",
        "dataset. Unlike `batch()` or `padded_batch()`, batches from\n",
        "`shuffle_repeat_batch()` always contain exactly `batch_size` examples. Also\n",
        "unlike TensorFlow, that holds even when `drop_remainder=False`.\n",
        "\n",
        "By default the iteration stops after the first epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 59,
          "status": "ok",
          "timestamp": 1631285621158,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "KlXliT7vawQa",
        "outputId": "09a83f46-e45c-4b0f-a902-c05dc8f36d40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# batches\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('# batches')\n",
        "len(list(client_dataset.shuffle_repeat_batch(batch_size=8)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHMy2bUzaPH9"
      },
      "source": [
        "The number of batches produced from the iteration can be controlled by the `(num_epochs, num_steps,\n",
        "drop_remainder)` combination:\n",
        "\n",
        "If both `num_epochs` and `num_steps` are None, the shuffle-repeat process continues forever.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 11,
          "status": "ok",
          "timestamp": 1631285629811,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "2PLFH_zCbfmr",
        "outputId": "c71d44ce-953f-4116-9e8d-6df0ebcf5edb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "infinite_bs = client_dataset.shuffle_repeat_batch(\n",
        "    batch_size=8, num_epochs=None, num_steps=None)\n",
        "for i, b in zip(range(6), infinite_bs):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtdePTEobgEL"
      },
      "source": [
        "If `num_epochs` is set and `num_steps` is None, as few batches as needed to go\n",
        "over the dataset this many passes are produced. Further,\n",
        "\n",
        "-   If `drop_remainder` is False (the default), the final batch is filled with\n",
        "    additionally sampled examples to contain `batch_size` examples.\n",
        "-   If `drop_remainder` is True, the final batch is dropped if it contains fewer\n",
        "    than `batch_size` examples. This may result in examples being skipped when\n",
        "    `num_epochs=1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 59,
          "status": "ok",
          "timestamp": 1631285660898,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "xTUDo9E2blJk",
        "outputId": "fb607564-df14-4562-fdd6-63362235ffcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# batches w/ drop_remainder=False\n",
            "3\n",
            "# batches w/ drop_remainder=True\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "print('# batches w/ drop_remainder=False')\n",
        "print(len(list(client_dataset.shuffle_repeat_batch(batch_size=8, num_epochs=1, num_steps=None))))\n",
        "print('# batches w/ drop_remainder=True')\n",
        "print(len(list(client_dataset.shuffle_repeat_batch(batch_size=8, num_epochs=1, num_steps=None, drop_remainder=True))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxYReBTkblZN"
      },
      "source": [
        "If `num_steps` is set and `num_steps` is None, exactly this many batches are\n",
        "produced. `drop_remainder` has no effect in this case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 161,
          "status": "ok",
          "timestamp": 1631285674525,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "QNPvIWdTbnp4",
        "outputId": "e508fb57-4436-450e-dacd-9d280736d98c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# batches w/ num_steps set and drop_remainder=True\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "print('# batches w/ num_steps set and drop_remainder=True')\n",
        "print(len(list(client_dataset.shuffle_repeat_batch(batch_size=8, num_epochs=None, num_steps=3, drop_remainder=True))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qARHz3mPbn26"
      },
      "source": [
        "If both `num_epochs` and `num_steps` are set, the fewer number of batches\n",
        "between the two conditions are produced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 9,
          "status": "ok",
          "timestamp": 1631285677477,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "dMt9WOaQbpry",
        "outputId": "a57d64ac-adf8-48b4-8eea-1998dd435a8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# batches w/ num_epochs and num_steps set\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "print('# batches w/ num_epochs and num_steps set')\n",
        "print(len(list(client_dataset.shuffle_repeat_batch(batch_size=8, num_epochs=1, num_steps=6))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ptjP1zwalp7"
      },
      "source": [
        "If reproducible iteration order is desired, a fixed `seed` can be used. When\n",
        "`seed` is None, repeated iteration over the same object may produce batches in a\n",
        "different order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 61,
          "status": "ok",
          "timestamp": 1631285692335,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "lIZjo5F4bsLO",
        "outputId": "681a2e53-829d-4bdb-b4e0-de50926c94e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'x': array([[78, 29, 75, 78, 33, 16, 66, 47],\n",
            "       [ 7, 26, 47, 27, 42, 16,  7,  4]], dtype=int32), 'y': array([[29, 75, 78, 33, 16, 66, 47,  3],\n",
            "       [26, 47, 27, 42, 16,  7,  4, 67]], dtype=int32)}\n",
            "{'x': array([[16, 14,  4, 67, 47, 16, 48, 67],\n",
            "       [48, 16, 13, 32, 33, 14, 11, 78]], dtype=int32), 'y': array([[14,  4, 67, 47, 16, 48, 67, 84],\n",
            "       [16, 13, 32, 33, 14, 11, 78, 76]], dtype=int32)}\n"
          ]
        }
      ],
      "source": [
        "# Random shuffling.\n",
        "print(list(client_dataset.shuffle_repeat_batch(batch_size=2, seed=None))[0])\n",
        "# Fixed shuffling.\n",
        "print(list(client_dataset.shuffle_repeat_batch(batch_size=2, seed=0))[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybw5LyduIuDC"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "Going from the raw features to features in a batch of examples ready for use in training/evalution often requires a few steps of preprocessing. Sometimes, we also want to add new preprocessing to an existing `FederatedData`.\n",
        "\n",
        "Before going into the details of preprocessing, please note once again that all dataset related operations should be implemented in standard NumPy, not in JAX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QH9O7_2SMQj"
      },
      "source": [
        "### Preprocessing a batch of examples\n",
        "\n",
        "The easiest way to add an additional preprocessing step is by appending a function that transforms a batch of examples to a `FederatedData`'s list of preprocessing transformations on batches.\n",
        "\n",
        "Below, we add a new `z` feature that stores the parity of `y` for our Shakespeare examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 59,
          "status": "ok",
          "timestamp": 1631287557956,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "h9LTxiFGTmgx",
        "outputId": "2a9c90e1-12b3-47e9-c03f-93e9daaed65c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'z': array([[1, 1, 0, 1, 1, 1, 1, 0],\n",
              "        [0, 1, 0, 1, 0, 1, 0, 0],\n",
              "        [0, 1, 1, 0, 0, 1, 1, 0],\n",
              "        [1, 1, 1, 0, 1, 1, 1, 0]], dtype=int32),\n",
              " 'x': array([[ 1, 55, 67, 84, 67, 47,  7, 67],\n",
              "        [48, 16, 13, 32, 33, 14, 11, 78],\n",
              "        [76, 78, 33, 19, 16, 66, 47,  3],\n",
              "        [16, 27, 67, 23, 26, 47,  3, 27]], dtype=int32),\n",
              " 'y': array([[55, 67, 84, 67, 47,  7, 67, 48],\n",
              "        [16, 13, 32, 33, 14, 11, 78, 76],\n",
              "        [78, 33, 19, 16, 66, 47,  3, 16],\n",
              "        [27, 67, 23, 26, 47,  3, 27, 16]], dtype=int32),\n",
              " '__mask__': array([ True,  True,  True,  True])}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# A preprocessing function should return a new dict of examples instead of\n",
        "# modifying its input.\n",
        "def parity_feature(examples):\n",
        "  return {'z': examples['y'] % 2, **examples}\n",
        "\n",
        "# preprocess_batch returns a new FederatedData object that has one more\n",
        "# preprocessing step at the very end than the original.\n",
        "train_fd_z = train_fd.preprocess_batch(parity_feature)\n",
        "client_id = b'105f96df763d4ddf:ALL_S_WELL_THAT_ENDS_WELL_GUIDERIUS_AND_ARVIRAGUS'\n",
        "next(iter(train_fd_z.get_client(client_id).padded_batch(batch_size=4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbh_cXCTUj9L"
      },
      "source": [
        "### Preprocessing at the client level\n",
        "\n",
        "Sometimes we also need to do some preprocessing for the entire client dataset. For example, in the Shakespeare dataset, the raw features are just text strings, so we need to turn them into a NumPy array of chunks of integer labels just to be able to meaningfully batch them at all.\n",
        "\n",
        "In most circumstances, adding a preprocessing step at the client level is unnecessary, and should be avoided, because the new preprocessing step added by `preprocess_client` is inserted into the middle of a chain of steps, just before all the batch level preprocessing steps registered by `preprocess_batch`. If not done carefully, a custom client level preprocessing can easily break the preprocessing chain.\n",
        "\n",
        "Nevertheless, here's an example of client level processing for certain rare cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 17,
          "status": "ok",
          "timestamp": 1631288075919,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "owvH0JlqgQef",
        "outputId": "c45d7a6f-a587-46b1-a39a-a5e6559e73df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing cached file '/tmp/.cache/fedjax/shakespeare_train.sqlite'\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'snippets': array([b'Re-enter POSTHUMUS, and seconds the Britons; they rescue\\nCYMBELINE, and exeunt. Then re-enter LUCIUS and IACHIMO,\\n                     with IMOGEN\\n'],\n",
              "       dtype=object)}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load unpreprocessed data.\n",
        "raw_fd = fedjax.datasets.shakespeare.load_split('train')\n",
        "raw_fd.get_client(client_id).all_examples()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0laSNlsBWoOp"
      },
      "source": [
        "The actual client level preprocessing in the Shakespeare dataset is a bit involved, so let's do something simpler: we shall join all the snippets, and then split and pad the integer byte values into bounded length sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 160,
          "status": "ok",
          "timestamp": 1631289386267,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "aj1Zql7MW2IK",
        "outputId": "9090e82a-a0e9-46eb-d8a4-9ad44aee49a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'snippets': array([[ 82, 101,  45, 101, 110, 116, 101, 114,  32,  80],\n",
              "        [ 79,  83,  84,  72,  85,  77,  85,  83,  44,  32],\n",
              "        [ 97, 110, 100,  32, 115, 101,  99, 111, 110, 100],\n",
              "        [115,  32, 116, 104, 101,  32,  66, 114, 105, 116],\n",
              "        [111, 110, 115,  59,  32, 116, 104, 101, 121,  32],\n",
              "        [114, 101, 115,  99, 117, 101,  10,  67,  89,  77],\n",
              "        [ 66,  69,  76,  73,  78,  69,  44,  32,  97, 110],\n",
              "        [100,  32, 101, 120, 101, 117, 110, 116,  46,  32],\n",
              "        [ 84, 104, 101, 110,  32, 114, 101,  45, 101, 110],\n",
              "        [116, 101, 114,  32,  76,  85,  67,  73,  85,  83],\n",
              "        [ 32,  97, 110, 100,  32,  73,  65,  67,  72,  73],\n",
              "        [ 77,  79,  44,  10,  32,  32,  32,  32,  32,  32],\n",
              "        [ 32,  32,  32,  32,  32,  32,  32,  32,  32,  32],\n",
              "        [ 32,  32,  32,  32,  32, 119, 105, 116, 104,  32],\n",
              "        [ 73,  77,  79,  71,  69,  78,  10,   0,   0,   0]], dtype=int32)}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We don't actually need client_id, but `FederatedData` supplies it so that\n",
        "# different processing based on clients can be done.\n",
        "def truncate_and_cast(client_id, examples, max_length=10):\n",
        "  labels = list(b''.join(examples['snippets']))\n",
        "  num_sequences = (len(labels) + max_length - 1) // max_length\n",
        "  padded = np.zeros((num_sequences, max_length), dtype=np.int32)\n",
        "  for i in range(num_sequences):\n",
        "    chars = labels[i * max_length:(i + 1) * max_length]\n",
        "    padded[i, :len(chars)] = chars\n",
        "  return {'snippets': padded}\n",
        "\n",
        "\n",
        "partial_fd = raw_fd.preprocess_client(truncate_and_cast)\n",
        "partial_fd.get_client(client_id).all_examples()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbBYrRm6a-0p"
      },
      "source": [
        "Now, we can add another batch level preprocessor to produce `x` and `y` labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 7,
          "status": "ok",
          "timestamp": 1631289451744,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "5-AOIJQia9YL",
        "outputId": "0ff12835-2b1d-46ea-8bc6-f8b7ccee2b01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'x': array([[ 82, 101,  45, 101, 110, 116, 101, 114,  32],\n",
              "        [ 79,  83,  84,  72,  85,  77,  85,  83,  44],\n",
              "        [ 97, 110, 100,  32, 115, 101,  99, 111, 110],\n",
              "        [115,  32, 116, 104, 101,  32,  66, 114, 105],\n",
              "        [111, 110, 115,  59,  32, 116, 104, 101, 121],\n",
              "        [114, 101, 115,  99, 117, 101,  10,  67,  89],\n",
              "        [ 66,  69,  76,  73,  78,  69,  44,  32,  97],\n",
              "        [100,  32, 101, 120, 101, 117, 110, 116,  46],\n",
              "        [ 84, 104, 101, 110,  32, 114, 101,  45, 101],\n",
              "        [116, 101, 114,  32,  76,  85,  67,  73,  85],\n",
              "        [ 32,  97, 110, 100,  32,  73,  65,  67,  72],\n",
              "        [ 77,  79,  44,  10,  32,  32,  32,  32,  32],\n",
              "        [ 32,  32,  32,  32,  32,  32,  32,  32,  32],\n",
              "        [ 32,  32,  32,  32,  32, 119, 105, 116, 104],\n",
              "        [ 73,  77,  79,  71,  69,  78,  10,   0,   0]], dtype=int32),\n",
              " 'y': array([[101,  45, 101, 110, 116, 101, 114,  32,  80],\n",
              "        [ 83,  84,  72,  85,  77,  85,  83,  44,  32],\n",
              "        [110, 100,  32, 115, 101,  99, 111, 110, 100],\n",
              "        [ 32, 116, 104, 101,  32,  66, 114, 105, 116],\n",
              "        [110, 115,  59,  32, 116, 104, 101, 121,  32],\n",
              "        [101, 115,  99, 117, 101,  10,  67,  89,  77],\n",
              "        [ 69,  76,  73,  78,  69,  44,  32,  97, 110],\n",
              "        [ 32, 101, 120, 101, 117, 110, 116,  46,  32],\n",
              "        [104, 101, 110,  32, 114, 101,  45, 101, 110],\n",
              "        [101, 114,  32,  76,  85,  67,  73,  85,  83],\n",
              "        [ 97, 110, 100,  32,  73,  65,  67,  72,  73],\n",
              "        [ 79,  44,  10,  32,  32,  32,  32,  32,  32],\n",
              "        [ 32,  32,  32,  32,  32,  32,  32,  32,  32],\n",
              "        [ 32,  32,  32,  32, 119, 105, 116, 104,  32],\n",
              "        [ 77,  79,  71,  69,  78,  10,   0,   0,   0]], dtype=int32)}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def snippets_to_xy(examples):\n",
        "  snippets = examples['snippets']\n",
        "  return {'x': snippets[:, :-1], 'y': snippets[:, 1:]}\n",
        "\n",
        "\n",
        "partial_fd.preprocess_batch(snippets_to_xy).get_client(client_id).all_examples()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS8DIlotEVjz"
      },
      "source": [
        "## In memory federated datasets\n",
        "\n",
        "In many scenarios, it is desirable to create a small custom federated dataset from a collection of NumPy arrays for quick experimentation. FedJAX provides `fedjax.InMemoryFederatedData` to create small custom datasets. `fedjax.InMemoryFederatedData` takes a dictionary of numpy examples keyed by client id and creates a `fedjax.FederatedData` that is compatible with the rest of the library. We illustrate this below with a simple example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 11532,
          "status": "ok",
          "timestamp": 1631285881039,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "UsKFk9eWE8HE",
        "outputId": "f25d446d-f215-4346-d247-4329a4d9a581"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features shape (60000, 28, 28, 1)\n",
            "labels shape (60000,)\n",
            "number of clients in iid_mnist_data 100\n"
          ]
        }
      ],
      "source": [
        "# Obtain MNIST dataset from tensorflow and convert to numpy format.\n",
        "import tensorflow_datasets as tfds\n",
        "(ds_train, ds_test) = tfds.load('mnist',\n",
        "                                split=['train', 'test'],\n",
        "                                shuffle_files=True,\n",
        "                                as_supervised=True,\n",
        "                                with_info=False)\n",
        "features, labels = list(ds_train.batch(60000).as_numpy_iterator())[0]\n",
        "print('features shape', features.shape)\n",
        "print('labels shape', labels.shape)\n",
        "\n",
        "# Randomly split dataset into 100 clients and load them to a dictionary.\n",
        "indices = np.random.randint(100, size=60000)\n",
        "client_id_to_dataset_mapping = {}\n",
        "for i in range(100):\n",
        "  client_id_to_dataset_mapping[i] = {'x': features[indices==i, :, : , :],\n",
        "                                     'y': labels[indices==i]}\n",
        "\n",
        "# Create fedjax.InMemoryDataset.\n",
        "iid_mnist_federated_data = fedjax.InMemoryFederatedData(\n",
        "    client_id_to_dataset_mapping)\n",
        "\n",
        "print('number of clients in iid_mnist_data',\n",
        "      iid_mnist_federated_data.num_clients())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV3azKfTHoH2"
      },
      "source": [
        "## Recap\n",
        "\n",
        "In this tutorial, we have covered the following:\n",
        "\n",
        "1. Using `fedjax.FederatedData`.\n",
        "2. Different ways of batching client datasets.\n",
        "3. Different ways of processing client datasets.\n",
        "4. Creating small custom federated datasets. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "name": "dataset_tutorial.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
